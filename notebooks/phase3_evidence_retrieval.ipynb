{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8136f10",
   "metadata": {},
   "source": [
    "# Phase 3 — Evidence Retrieval (Hybrid)\n",
    "\n",
    "This notebook tests and debugs the evidence retrieval pipeline:\n",
    "- Retrieve from trusted sources: PIB, WHO/health advisories, RBI, major news portals\n",
    "- Augment with Wikipedia + curated fact-check DB (cache in BigQuery)\n",
    "- Freshness: bias recent content (last 7–14 days)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028a4c1f",
   "metadata": {},
   "source": [
    "## Step 1: Setup and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920bc363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 3: Evidence Retrieval and Source Assessment\n",
    "# Updated to use actual TruthLens evidence retrieval modules\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import asyncio\n",
    "from datetime import datetime, timezone\n",
    "from typing import Dict, List, Optional, Union, Any, Tuple\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path for TruthLens modules\n",
    "project_root = Path().resolve()\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Import actual TruthLens evidence retrieval modules\n",
    "try:\n",
    "    # Phase 3 evidence retrieval modules\n",
    "    from phase3_evidence_retrieval.connectors.wikipedia import WikipediaConnector\n",
    "    from phase3_evidence_retrieval.connectors.factcheck import PIBFactCheckConnector, PolitiFactConnector\n",
    "    from phase3_evidence_retrieval.schemas.evidence import RawEvidence, SourceType, Language\n",
    "    from phase3_evidence_retrieval.scoring.evidence_score import score_evidence, ScoreWeights\n",
    "    \n",
    "    # Phase 4 evidence selection (part of retrieval pipeline)\n",
    "    from phase4_verification.src.evidence_selection import select_top_evidence, EvidenceItem\n",
    "    \n",
    "    # Pipeline modules\n",
    "    try:\n",
    "        from phase3_evidence_retrieval.pipeline.retrieve_pipeline import RetrievePipeline\n",
    "        pipeline_available = True\n",
    "    except:\n",
    "        pipeline_available = False\n",
    "        \n",
    "    print(\"✅ Successfully imported TruthLens evidence retrieval modules!\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"⚠️ Some evidence modules not available: {e}\")\n",
    "    print(\"Will use available modules and fallback implementations\")\n",
    "    WikipediaConnector = None\n",
    "    pipeline_available = False\n",
    "\n",
    "# Fallback imports from Phase 7 pipeline\n",
    "try:\n",
    "    from Phase_7.pipeline.retriever import EvidenceRetriever\n",
    "    phase7_available = True\n",
    "except:\n",
    "    phase7_available = False\n",
    "\n",
    "print(\"📊 Available evidence retrieval capabilities:\")\n",
    "print(f\"- Wikipedia Connector: {'✅' if WikipediaConnector else '❌'}\")\n",
    "print(f\"- Fact-check Connectors: {'✅' if 'PIBFactCheckConnector' in globals() else '❌'}\")\n",
    "print(f\"- Evidence Scoring: {'✅' if 'score_evidence' in globals() else '❌'}\")\n",
    "print(f\"- Complete Pipeline: {'✅' if pipeline_available else '❌'}\")\n",
    "print(f\"- Phase 7 Retriever: {'✅' if phase7_available else '❌'}\")\n",
    "\n",
    "# Test claims for evidence retrieval\n",
    "test_claims = {\n",
    "    'covid_vaccine': \"COVID-19 vaccines reduce hospitalization rates by 90%\",\n",
    "    'climate_change': \"Human activities are the primary cause of recent climate change\",\n",
    "    'conspiracy_5g': \"5G towers cause COVID-19 symptoms and health problems\",\n",
    "    'medical_misinformation': \"Drinking bleach can cure COVID-19\",\n",
    "    'political_claim': \"The 2020 US election was rigged with widespread voter fraud\",\n",
    "    'factual_science': \"Water boils at 100 degrees Celsius at sea level pressure\",\n",
    "    'economic_claim': \"Inflation in the US reached 9.1% in June 2022\"\n",
    "}\n",
    "\n",
    "print(f\"\\n🎯 Test claims prepared: {len(test_claims)} examples\")\n",
    "for key, claim in test_claims.items():\n",
    "    print(f\"- {key}: {claim[:60]}...\")\n",
    "    \n",
    "print(\"\\n🔍 Phase 3 testing will cover:\")\n",
    "print(\"1. Wikipedia Background Search\")\n",
    "print(\"2. Fact-check Source Retrieval\")  \n",
    "print(\"3. Evidence Relevance Scoring\")\n",
    "print(\"4. Source Quality Assessment\")\n",
    "print(\"5. Multi-source Evidence Aggregation\")\n",
    "print(\"6. Evidence Selection and Ranking\")\n",
    "print(\"7. Complete Retrieval Pipeline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea25c20",
   "metadata": {},
   "source": [
    "## Step 2: Trusted Source Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adf178f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for trusted sources\n",
    "TRUSTED_SOURCES = {\n",
    "    'government': {\n",
    "        'pib': {\n",
    "            'name': 'Press Information Bureau (PIB)',\n",
    "            'base_url': 'https://pib.gov.in',\n",
    "            'rss_feeds': [\n",
    "                'https://pib.gov.in/rss.aspx',\n",
    "                'https://pib.gov.in/RSS.aspx?m=Health&ln=1'\n",
    "            ],\n",
    "            'search_url': 'https://pib.gov.in/Pressreleasesearch.aspx',\n",
    "            'credibility_score': 0.95\n",
    "        },\n",
    "        'mohfw': {\n",
    "            'name': 'Ministry of Health and Family Welfare',\n",
    "            'base_url': 'https://www.mohfw.gov.in',\n",
    "            'rss_feeds': [\n",
    "                'https://www.mohfw.gov.in/RSS.xml'\n",
    "            ],\n",
    "            'credibility_score': 0.95\n",
    "        },\n",
    "        'rbi': {\n",
    "            'name': 'Reserve Bank of India',\n",
    "            'base_url': 'https://www.rbi.org.in',\n",
    "            'rss_feeds': [\n",
    "                'https://www.rbi.org.in/RSS.xml'\n",
    "            ],\n",
    "            'credibility_score': 0.95\n",
    "        }\n",
    "    },\n",
    "    'international': {\n",
    "        'who': {\n",
    "            'name': 'World Health Organization',\n",
    "            'base_url': 'https://www.who.int',\n",
    "            'rss_feeds': [\n",
    "                'https://www.who.int/rss-feeds/news-english.xml'\n",
    "            ],\n",
    "            'credibility_score': 0.95\n",
    "        },\n",
    "        'cdc': {\n",
    "            'name': 'Centers for Disease Control and Prevention',\n",
    "            'base_url': 'https://www.cdc.gov',\n",
    "            'rss_feeds': [\n",
    "                'https://tools.cdc.gov/api/v2/resources/media.rss'\n",
    "            ],\n",
    "            'credibility_score': 0.95\n",
    "        }\n",
    "    },\n",
    "    'media': {\n",
    "        'reuters': {\n",
    "            'name': 'Reuters',\n",
    "            'base_url': 'https://www.reuters.com',\n",
    "            'rss_feeds': [\n",
    "                'https://www.reuters.com/arcio/rss/'\n",
    "            ],\n",
    "            'credibility_score': 0.85\n",
    "        },\n",
    "        'bbc': {\n",
    "            'name': 'BBC',\n",
    "            'base_url': 'https://www.bbc.com',\n",
    "            'rss_feeds': [\n",
    "                'http://feeds.bbci.co.uk/news/rss.xml'\n",
    "            ],\n",
    "            'credibility_score': 0.85\n",
    "        }\n",
    "    },\n",
    "    'factcheck': {\n",
    "        'snopes': {\n",
    "            'name': 'Snopes',\n",
    "            'base_url': 'https://www.snopes.com',\n",
    "            'credibility_score': 0.80\n",
    "        },\n",
    "        'factcheck_org': {\n",
    "            'name': 'FactCheck.org',\n",
    "            'base_url': 'https://www.factcheck.org',\n",
    "            'credibility_score': 0.85\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Trusted sources configuration loaded:\")\n",
    "for category, sources in TRUSTED_SOURCES.items():\n",
    "    print(f\"  {category}: {list(sources.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b659170",
   "metadata": {},
   "source": [
    "## Step 3: RSS Feed Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b250f0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_rss_feeds(source_config: Dict, max_articles: int = 20) -> List[Dict]:\n",
    "    \"\"\"Fetch articles from RSS feeds\"\"\"\n",
    "    articles = []\n",
    "    \n",
    "    for feed_url in source_config.get('rss_feeds', []):\n",
    "        try:\n",
    "            # Parse RSS feed\n",
    "            feed = feedparser.parse(feed_url)\n",
    "            \n",
    "            for entry in feed.entries[:max_articles]:\n",
    "                # Extract article metadata\n",
    "                published_date = None\n",
    "                if hasattr(entry, 'published_parsed') and entry.published_parsed:\n",
    "                    published_date = datetime(*entry.published_parsed[:6])\n",
    "                elif hasattr(entry, 'updated_parsed') and entry.updated_parsed:\n",
    "                    published_date = datetime(*entry.updated_parsed[:6])\n",
    "                \n",
    "                article = {\n",
    "                    'title': entry.get('title', ''),\n",
    "                    'url': entry.get('link', ''),\n",
    "                    'summary': entry.get('summary', ''),\n",
    "                    'published_date': published_date,\n",
    "                    'source_name': source_config['name'],\n",
    "                    'credibility_score': source_config['credibility_score'],\n",
    "                    'feed_url': feed_url,\n",
    "                    'content_type': 'rss_article'\n",
    "                }\n",
    "                \n",
    "                articles.append(article)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching RSS feed {feed_url}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    return articles\n",
    "\n",
    "# Test RSS feed retrieval (mocked for demo)\n",
    "def mock_rss_articles():\n",
    "    \"\"\"Generate mock RSS articles for testing\"\"\"\n",
    "    mock_articles = [\n",
    "        {\n",
    "            'title': 'WHO Updates COVID-19 Vaccine Safety Guidelines',\n",
    "            'url': 'https://www.who.int/news/item/covid-vaccine-safety',\n",
    "            'summary': 'WHO releases new guidelines on COVID-19 vaccine safety monitoring and adverse event reporting.',\n",
    "            'published_date': datetime.now() - timedelta(days=2),\n",
    "            'source_name': 'World Health Organization',\n",
    "            'credibility_score': 0.95,\n",
    "            'content_type': 'rss_article'\n",
    "        },\n",
    "        {\n",
    "            'title': 'PIB Fact Check: No Evidence of 80% Severe Side Effects from COVID Vaccines',\n",
    "            'url': 'https://pib.gov.in/factcheck/covid-vaccine-side-effects',\n",
    "            'summary': 'PIB fact-checking unit debunks false claims about COVID vaccine side effects.',\n",
    "            'published_date': datetime.now() - timedelta(days=1),\n",
    "            'source_name': 'Press Information Bureau (PIB)',\n",
    "            'credibility_score': 0.95,\n",
    "            'content_type': 'rss_article'\n",
    "        },\n",
    "        {\n",
    "            'title': 'Cancer Research: New Treatment Shows Promise in Clinical Trials',\n",
    "            'url': 'https://www.reuters.com/health/cancer-treatment-trials',\n",
    "            'summary': 'Researchers report positive results from Phase 2 clinical trials of new cancer treatment.',\n",
    "            'published_date': datetime.now() - timedelta(days=5),\n",
    "            'source_name': 'Reuters',\n",
    "            'credibility_score': 0.85,\n",
    "            'content_type': 'rss_article'\n",
    "        }\n",
    "    ]\n",
    "    return mock_articles\n",
    "\n",
    "# Get mock articles\n",
    "mock_articles = mock_rss_articles()\n",
    "print(\"Mock RSS articles retrieved:\")\n",
    "for article in mock_articles:\n",
    "    print(f\"  - {article['title']} ({article['source_name']})\")\n",
    "    print(f\"    Published: {article['published_date'].strftime('%Y-%m-%d')}\")\n",
    "    print(f\"    Credibility: {article['credibility_score']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e194d23",
   "metadata": {},
   "source": [
    "## Step 4: Wikipedia Search and Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe45212",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_wikipedia(query: str, max_results: int = 3) -> List[Dict]:\n",
    "    \"\"\"Search Wikipedia for relevant articles\"\"\"\n",
    "    wikipedia_articles = []\n",
    "    \n",
    "    try:\n",
    "        # Search for relevant pages\n",
    "        search_results = wikipedia.search(query, results=max_results)\n",
    "        \n",
    "        for title in search_results:\n",
    "            try:\n",
    "                # Get page summary\n",
    "                page = wikipedia.page(title)\n",
    "                \n",
    "                article = {\n",
    "                    'title': page.title,\n",
    "                    'url': page.url,\n",
    "                    'summary': page.summary[:500],  # First 500 chars\n",
    "                    'content': page.content[:2000],  # First 2000 chars\n",
    "                    'published_date': None,  # Wikipedia doesn't have clear publication dates\n",
    "                    'source_name': 'Wikipedia',\n",
    "                    'credibility_score': 0.75,  # Medium credibility\n",
    "                    'content_type': 'wikipedia_article',\n",
    "                    'categories': getattr(page, 'categories', [])[:5]  # First 5 categories\n",
    "                }\n",
    "                \n",
    "                wikipedia_articles.append(article)\n",
    "                \n",
    "            except wikipedia.exceptions.DisambiguationError as e:\n",
    "                # Handle disambiguation pages by taking the first option\n",
    "                try:\n",
    "                    page = wikipedia.page(e.options[0])\n",
    "                    article = {\n",
    "                        'title': page.title,\n",
    "                        'url': page.url,\n",
    "                        'summary': page.summary[:500],\n",
    "                        'content': page.content[:2000],\n",
    "                        'published_date': None,\n",
    "                        'source_name': 'Wikipedia',\n",
    "                        'credibility_score': 0.75,\n",
    "                        'content_type': 'wikipedia_article'\n",
    "                    }\n",
    "                    wikipedia_articles.append(article)\n",
    "                except:\n",
    "                    continue\n",
    "                    \n",
    "            except (wikipedia.exceptions.PageError, wikipedia.exceptions.WikipediaException):\n",
    "                continue\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Error searching Wikipedia: {str(e)}\")\n",
    "    \n",
    "    return wikipedia_articles\n",
    "\n",
    "# Test Wikipedia search (mocked for demo)\n",
    "def mock_wikipedia_search(query: str) -> List[Dict]:\n",
    "    \"\"\"Generate mock Wikipedia results for testing\"\"\"\n",
    "    mock_results = {\n",
    "        'covid vaccine': [\n",
    "            {\n",
    "                'title': 'COVID-19 vaccine',\n",
    "                'url': 'https://en.wikipedia.org/wiki/COVID-19_vaccine',\n",
    "                'summary': 'COVID-19 vaccines are vaccines intended to provide immunity against SARS-CoV-2...',\n",
    "                'content': 'COVID-19 vaccines have been shown to be safe and effective in clinical trials...',\n",
    "                'source_name': 'Wikipedia',\n",
    "                'credibility_score': 0.75,\n",
    "                'content_type': 'wikipedia_article'\n",
    "            }\n",
    "        ],\n",
    "        'cancer cure': [\n",
    "            {\n",
    "                'title': 'Cancer treatment',\n",
    "                'url': 'https://en.wikipedia.org/wiki/Cancer_treatment',\n",
    "                'summary': 'Cancer treatment includes various methods to treat cancer patients...',\n",
    "                'content': 'Cancer treatment varies depending on the type and stage of cancer...',\n",
    "                'source_name': 'Wikipedia',\n",
    "                'credibility_score': 0.75,\n",
    "                'content_type': 'wikipedia_article'\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Simple keyword matching for demo\n",
    "    query_lower = query.lower()\n",
    "    if 'covid' in query_lower or 'vaccine' in query_lower:\n",
    "        return mock_results['covid vaccine']\n",
    "    elif 'cancer' in query_lower or 'cure' in query_lower:\n",
    "        return mock_results['cancer cure']\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "# Test Wikipedia search\n",
    "print(\"Wikipedia search results:\")\n",
    "for claim in test_claims[:2]:  # Test first 2 claims\n",
    "    wiki_results = mock_wikipedia_search(claim)\n",
    "    print(f\"\\nQuery: {claim}\")\n",
    "    for result in wiki_results:\n",
    "        print(f\"  - {result['title']}\")\n",
    "        print(f\"    Summary: {result['summary'][:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c07165",
   "metadata": {},
   "source": [
    "## Step 5: Semantic Similarity and Relevance Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba0be58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_relevance_score(claim: str, article: Dict) -> float:\n",
    "    \"\"\"Calculate relevance score between claim and article using TF-IDF similarity\"\"\"\n",
    "    try:\n",
    "        # Combine article title and summary for comparison\n",
    "        article_text = f\"{article.get('title', '')} {article.get('summary', '')}\"\n",
    "        \n",
    "        # Create TF-IDF vectors\n",
    "        vectorizer = TfidfVectorizer(stop_words='english', max_features=1000)\n",
    "        tfidf_matrix = vectorizer.fit_transform([claim, article_text])\n",
    "        \n",
    "        # Calculate cosine similarity\n",
    "        similarity = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])[0][0]\n",
    "        \n",
    "        return float(similarity)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating relevance score: {str(e)}\")\n",
    "        return 0.0\n",
    "\n",
    "def calculate_freshness_score(article: Dict, max_age_days: int = 14) -> float:\n",
    "    \"\"\"Calculate freshness score based on article publication date\"\"\"\n",
    "    if not article.get('published_date'):\n",
    "        return 0.5  # Neutral score for articles without dates\n",
    "    \n",
    "    # Calculate age in days\n",
    "    age_days = (datetime.now() - article['published_date']).days\n",
    "    \n",
    "    if age_days <= max_age_days:\n",
    "        # Linear decay from 1.0 to 0.5 over max_age_days\n",
    "        return 1.0 - (age_days / max_age_days) * 0.5\n",
    "    else:\n",
    "        # Exponential decay after max_age_days\n",
    "        return 0.5 * np.exp(-(age_days - max_age_days) / 30)\n",
    "\n",
    "def score_evidence_article(claim: str, article: Dict) -> Dict:\n",
    "    \"\"\"Score an evidence article for relevance, credibility, and freshness\"\"\"\n",
    "    # Calculate individual scores\n",
    "    relevance_score = calculate_relevance_score(claim, article)\n",
    "    credibility_score = article.get('credibility_score', 0.5)\n",
    "    freshness_score = calculate_freshness_score(article)\n",
    "    \n",
    "    # Calculate weighted overall score\n",
    "    weights = {\n",
    "        'relevance': 0.5,\n",
    "        'credibility': 0.3,\n",
    "        'freshness': 0.2\n",
    "    }\n",
    "    \n",
    "    overall_score = (\n",
    "        relevance_score * weights['relevance'] +\n",
    "        credibility_score * weights['credibility'] +\n",
    "        freshness_score * weights['freshness']\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'article': article,\n",
    "        'scores': {\n",
    "            'relevance': relevance_score,\n",
    "            'credibility': credibility_score,\n",
    "            'freshness': freshness_score,\n",
    "            'overall': overall_score\n",
    "        },\n",
    "        'claim': claim\n",
    "    }\n",
    "\n",
    "# Test evidence scoring\n",
    "test_claim = \"The new COVID vaccine causes severe side effects in 80% of patients\"\n",
    "test_articles = mock_rss_articles() + mock_wikipedia_search(test_claim)\n",
    "\n",
    "print(\"Evidence article scoring results:\")\n",
    "print(f\"Claim: {test_claim}\\n\")\n",
    "\n",
    "scored_articles = []\n",
    "for article in test_articles:\n",
    "    scored_article = score_evidence_article(test_claim, article)\n",
    "    scored_articles.append(scored_article)\n",
    "    \n",
    "    print(f\"Article: {article['title']}\")\n",
    "    print(f\"  Source: {article['source_name']}\")\n",
    "    print(f\"  Relevance: {scored_article['scores']['relevance']:.3f}\")\n",
    "    print(f\"  Credibility: {scored_article['scores']['credibility']:.3f}\")\n",
    "    print(f\"  Freshness: {scored_article['scores']['freshness']:.3f}\")\n",
    "    print(f\"  Overall Score: {scored_article['scores']['overall']:.3f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0612854d",
   "metadata": {},
   "source": [
    "## Step 6: Evidence Ranking and Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599cd0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_and_select_evidence(claim: str, articles: List[Dict], top_k: int = 3) -> List[Dict]:\n",
    "    \"\"\"Rank articles by overall score and select top evidence\"\"\"\n",
    "    # Score all articles\n",
    "    scored_articles = []\n",
    "    for article in articles:\n",
    "        scored_article = score_evidence_article(claim, article)\n",
    "        scored_articles.append(scored_article)\n",
    "    \n",
    "    # Sort by overall score (descending)\n",
    "    scored_articles.sort(key=lambda x: x['scores']['overall'], reverse=True)\n",
    "    \n",
    "    # Select top k articles\n",
    "    top_evidence = scored_articles[:top_k]\n",
    "    \n",
    "    # Add ranking information\n",
    "    for i, evidence in enumerate(top_evidence):\n",
    "        evidence['rank'] = i + 1\n",
    "        evidence['selected'] = True\n",
    "    \n",
    "    return top_evidence\n",
    "\n",
    "def extract_relevant_snippets(claim: str, article_content: str, max_snippets: int = 2) -> List[str]:\n",
    "    \"\"\"Extract relevant snippets from article content\"\"\"\n",
    "    # Split content into sentences\n",
    "    sentences = re.split(r'[.!?]+', article_content)\n",
    "    sentences = [s.strip() for s in sentences if s.strip() and len(s.split()) > 5]\n",
    "    \n",
    "    if not sentences:\n",
    "        return []\n",
    "    \n",
    "    # Calculate similarity for each sentence\n",
    "    sentence_scores = []\n",
    "    for sentence in sentences:\n",
    "        try:\n",
    "            # Simple keyword overlap scoring\n",
    "            claim_words = set(claim.lower().split())\n",
    "            sentence_words = set(sentence.lower().split())\n",
    "            overlap = len(claim_words & sentence_words)\n",
    "            score = overlap / len(claim_words) if claim_words else 0\n",
    "            sentence_scores.append((sentence, score))\n",
    "        except:\n",
    "            sentence_scores.append((sentence, 0))\n",
    "    \n",
    "    # Sort by score and select top snippets\n",
    "    sentence_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    top_snippets = [sentence for sentence, score in sentence_scores[:max_snippets] if score > 0]\n",
    "    \n",
    "    return top_snippets\n",
    "\n",
    "# Test evidence ranking and selection\n",
    "print(\"Evidence ranking and selection:\")\n",
    "print(f\"Claim: {test_claim}\\n\")\n",
    "\n",
    "top_evidence = rank_and_select_evidence(test_claim, test_articles)\n",
    "\n",
    "for evidence in top_evidence:\n",
    "    article = evidence['article']\n",
    "    print(f\"Rank {evidence['rank']}: {article['title']}\")\n",
    "    print(f\"  Source: {article['source_name']}\")\n",
    "    print(f\"  URL: {article['url']}\")\n",
    "    print(f\"  Overall Score: {evidence['scores']['overall']:.3f}\")\n",
    "    \n",
    "    # Extract relevant snippets\n",
    "    content = article.get('content', article.get('summary', ''))\n",
    "    snippets = extract_relevant_snippets(test_claim, content)\n",
    "    if snippets:\n",
    "        print(f\"  Key snippets:\")\n",
    "        for snippet in snippets:\n",
    "            print(f\"    - {snippet[:150]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f6d253",
   "metadata": {},
   "source": [
    "## Step 7: Complete Phase 3 Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c1973c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def phase3_pipeline(claims: List[str], max_evidence_per_claim: int = 3) -> Dict:\n",
    "    \"\"\"Complete Phase 3 pipeline: Evidence Retrieval\"\"\"\n",
    "    pipeline_result = {\n",
    "        'phase': 'Phase 3 - Evidence Retrieval (Hybrid)',\n",
    "        'input_claims': claims,\n",
    "        'steps': [],\n",
    "        'evidence_by_claim': {}\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Step 1: Fetch from trusted sources (RSS feeds)\n",
    "        all_rss_articles = mock_rss_articles()  # In production, fetch from actual RSS feeds\n",
    "        pipeline_result['steps'].append({\n",
    "            'step': 'rss_feed_retrieval',\n",
    "            'result': {\n",
    "                'articles_retrieved': len(all_rss_articles),\n",
    "                'sources': list(set([a['source_name'] for a in all_rss_articles]))\n",
    "            }\n",
    "        })\n",
    "        \n",
    "        # Step 2: Process each claim\n",
    "        for claim in claims:\n",
    "            claim_evidence = {\n",
    "                'claim': claim,\n",
    "                'evidence_sources': []\n",
    "            }\n",
    "            \n",
    "            # Get RSS articles for this claim\n",
    "            rss_evidence = rank_and_select_evidence(claim, all_rss_articles, max_evidence_per_claim)\n",
    "            \n",
    "            # Get Wikipedia articles for this claim\n",
    "            wiki_articles = mock_wikipedia_search(claim)\n",
    "            wiki_evidence = rank_and_select_evidence(claim, wiki_articles, 1)  # Max 1 Wikipedia result\n",
    "            \n",
    "            # Combine and re-rank all evidence\n",
    "            all_evidence = rss_evidence + wiki_evidence\n",
    "            all_evidence.sort(key=lambda x: x['scores']['overall'], reverse=True)\n",
    "            \n",
    "            # Select final evidence\n",
    "            final_evidence = all_evidence[:max_evidence_per_claim]\n",
    "            \n",
    "            # Format evidence for output\n",
    "            for i, evidence in enumerate(final_evidence):\n",
    "                article = evidence['article']\n",
    "                content = article.get('content', article.get('summary', ''))\n",
    "                snippets = extract_relevant_snippets(claim, content)\n",
    "                \n",
    "                evidence_item = {\n",
    "                    'rank': i + 1,\n",
    "                    'title': article['title'],\n",
    "                    'url': article['url'],\n",
    "                    'source_name': article['source_name'],\n",
    "                    'published_date': article.get('published_date'),\n",
    "                    'credibility_score': article['credibility_score'],\n",
    "                    'relevance_score': evidence['scores']['relevance'],\n",
    "                    'overall_score': evidence['scores']['overall'],\n",
    "                    'key_snippets': snippets,\n",
    "                    'content_type': article['content_type']\n",
    "                }\n",
    "                \n",
    "                claim_evidence['evidence_sources'].append(evidence_item)\n",
    "            \n",
    "            pipeline_result['evidence_by_claim'][claim] = claim_evidence\n",
    "        \n",
    "        # Step 3: Cache results (mock)\n",
    "        cache_info = {\n",
    "            'cached_articles': len(all_rss_articles) + sum(len(mock_wikipedia_search(c)) for c in claims),\n",
    "            'cache_timestamp': datetime.now().isoformat(),\n",
    "            'cache_ttl_hours': 24\n",
    "        }\n",
    "        \n",
    "        pipeline_result['steps'].append({\n",
    "            'step': 'evidence_caching',\n",
    "            'result': cache_info\n",
    "        })\n",
    "        \n",
    "        # Final summary\n",
    "        total_evidence = sum(len(claim_data['evidence_sources']) \n",
    "                           for claim_data in pipeline_result['evidence_by_claim'].values())\n",
    "        \n",
    "        pipeline_result['final_output'] = {\n",
    "            'claims_processed': len(claims),\n",
    "            'total_evidence_retrieved': total_evidence,\n",
    "            'ready_for_phase4': total_evidence > 0\n",
    "        }\n",
    "        pipeline_result['status'] = 'success'\n",
    "        \n",
    "    except Exception as e:\n",
    "        pipeline_result['error'] = str(e)\n",
    "        pipeline_result['status'] = 'failed'\n",
    "    \n",
    "    return pipeline_result\n",
    "\n",
    "# Test complete Phase 3 pipeline\n",
    "print(\"=== Testing Complete Phase 3 Pipeline ===\")\n",
    "phase3_result = phase3_pipeline(test_claims)\n",
    "\n",
    "# Print summary\n",
    "print(f\"Status: {phase3_result['status']}\")\n",
    "print(f\"Claims processed: {phase3_result['final_output']['claims_processed']}\")\n",
    "print(f\"Total evidence retrieved: {phase3_result['final_output']['total_evidence_retrieved']}\")\n",
    "print(f\"Ready for Phase 4: {phase3_result['final_output']['ready_for_phase4']}\")\n",
    "\n",
    "# Print evidence for each claim\n",
    "for claim, evidence_data in phase3_result['evidence_by_claim'].items():\n",
    "    print(f\"\\nClaim: {claim}\")\n",
    "    print(f\"Evidence sources found: {len(evidence_data['evidence_sources'])}\")\n",
    "    \n",
    "    for evidence in evidence_data['evidence_sources']:\n",
    "        print(f\"  {evidence['rank']}. {evidence['title']} ({evidence['source_name']})\")\n",
    "        print(f\"     Score: {evidence['overall_score']:.3f} | Credibility: {evidence['credibility_score']}\")\n",
    "        if evidence['key_snippets']:\n",
    "            print(f\"     Key snippet: {evidence['key_snippets'][0][:100]}...\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
