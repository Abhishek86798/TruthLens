{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29944cd5",
   "metadata": {},
   "source": [
    "# Phase 5 — User Explanation Layer\n",
    "\n",
    "This notebook tests and debugs the user explanation layer:\n",
    "- Highlight why misleading: e.g. clickbait headline, missing context\n",
    "- Show manipulation cues chips (fear appeal / cherry-picking)\n",
    "- Generate prebunk tip card (20s read) to educate user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4678510",
   "metadata": {},
   "source": [
    "## Step 1: Setup and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4242dfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(''))))\n",
    "\n",
    "import json\n",
    "import re\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "from enum import Enum\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "# Test data from Phase 4\n",
    "test_phase4_output = {\n",
    "    'claim': 'The new COVID vaccine causes severe side effects in 80% of patients',\n",
    "    'verdict': 'REFUTED',\n",
    "    'confidence': 0.85,\n",
    "    'confidence_badge': {'emoji': '🔴', 'label': 'Likely False', 'color': 'red'},\n",
    "    'certainty_level': 'High',\n",
    "    'citations': [\n",
    "        {\n",
    "            'id': 'citation_1',\n",
    "            'display_title': '❌ PIB Fact Check: No Evidence of 80% Severe Side Effects from COVID Vaccines',\n",
    "            'source': 'Press Information Bureau (PIB)',\n",
    "            'stance': 'REFUTED',\n",
    "            'highlighted_snippet': 'Clinical trials show **SIDE** **EFFECTS** occur in less than 5% of **PATIENTS** and are mostly mild...'\n",
    "        },\n",
    "        {\n",
    "            'id': 'citation_2', \n",
    "            'display_title': '❌ WHO Updates COVID-19 Vaccine Safety Guidelines',\n",
    "            'source': 'World Health Organization',\n",
    "            'stance': 'REFUTED',\n",
    "            'highlighted_snippet': 'Studies confirm **VACCINES** are safe with rare serious adverse events...'\n",
    "        }\n",
    "    ],\n",
    "    'evidence_summary': {\n",
    "        'total_sources': 2,\n",
    "        'stance_distribution': {'REFUTED': 2},\n",
    "        'avg_credibility': 0.95\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Dependencies loaded successfully!\")\n",
    "print(f\"Test claim: {test_phase4_output['claim']}\")\n",
    "print(f\"Verdict: {test_phase4_output['verdict']} ({test_phase4_output['confidence']:.2f} confidence)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78df1a98",
   "metadata": {},
   "source": [
    "## Step 2: Manipulation Cues Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3525edee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ManipulationCue(Enum):\n",
    "    FEAR_APPEAL = \"fear_appeal\"\n",
    "    CHERRY_PICKING = \"cherry_picking\"\n",
    "    FALSE_AUTHORITY = \"false_authority\"\n",
    "    EMOTIONAL_LANGUAGE = \"emotional_language\"\n",
    "    SPECIFIC_NUMBERS = \"specific_numbers\"\n",
    "    URGENCY = \"urgency\"\n",
    "    CONSPIRACY = \"conspiracy\"\n",
    "    BANDWAGON = \"bandwagon\"\n",
    "    OVERSIMPLIFICATION = \"oversimplification\"\n",
    "\n",
    "def detect_manipulation_cues(claim: str) -> List[Dict[str, any]]:\n",
    "    \"\"\"Detect manipulation techniques used in the claim\"\"\"\n",
    "    detected_cues = []\n",
    "    claim_lower = claim.lower()\n",
    "    \n",
    "    # Fear appeal detection\n",
    "    fear_keywords = [\n",
    "        'dangerous', 'deadly', 'harmful', 'toxic', 'severe', 'serious',\n",
    "        'devastating', 'catastrophic', 'alarming', 'shocking', 'terrifying'\n",
    "    ]\n",
    "    fear_matches = [word for word in fear_keywords if word in claim_lower]\n",
    "    if fear_matches:\n",
    "        detected_cues.append({\n",
    "            'type': ManipulationCue.FEAR_APPEAL.value,\n",
    "            'confidence': min(len(fear_matches) * 0.3, 1.0),\n",
    "            'evidence': fear_matches,\n",
    "            'description': 'Uses fear-inducing language to provoke emotional response'\n",
    "        })\n",
    "    \n",
    "    # Specific numbers (often used to appear authoritative)\n",
    "    number_pattern = r'\\b\\d+(?:\\.\\d+)?\\s*%|\\b\\d+\\s*percent|\\b\\d+\\s*out\\s*of\\s*\\d+'\n",
    "    number_matches = re.findall(number_pattern, claim)\n",
    "    if number_matches:\n",
    "        detected_cues.append({\n",
    "            'type': ManipulationCue.SPECIFIC_NUMBERS.value,\n",
    "            'confidence': 0.7,\n",
    "            'evidence': number_matches,\n",
    "            'description': 'Uses specific statistics without credible source'\n",
    "        })\n",
    "    \n",
    "    # Emotional language\n",
    "    emotional_keywords = [\n",
    "        'shocking', 'unbelievable', 'amazing', 'incredible', 'outrageous',\n",
    "        'scandalous', 'miraculous', 'breakthrough', 'revolutionary'\n",
    "    ]\n",
    "    emotional_matches = [word for word in emotional_keywords if word in claim_lower]\n",
    "    if emotional_matches:\n",
    "        detected_cues.append({\n",
    "            'type': ManipulationCue.EMOTIONAL_LANGUAGE.value,\n",
    "            'confidence': min(len(emotional_matches) * 0.4, 1.0),\n",
    "            'evidence': emotional_matches,\n",
    "            'description': 'Uses emotional language to bypass critical thinking'\n",
    "        })\n",
    "    \n",
    "    # False authority\n",
    "    vague_authority = [\n",
    "        'experts say', 'doctors warn', 'scientists claim', 'studies show',\n",
    "        'research proves', 'officials confirm'\n",
    "    ]\n",
    "    authority_matches = [phrase for phrase in vague_authority if phrase in claim_lower]\n",
    "    if authority_matches:\n",
    "        detected_cues.append({\n",
    "            'type': ManipulationCue.FALSE_AUTHORITY.value,\n",
    "            'confidence': min(len(authority_matches) * 0.5, 1.0),\n",
    "            'evidence': authority_matches,\n",
    "            'description': 'References vague authorities without specific citations'\n",
    "        })\n",
    "    \n",
    "    # Conspiracy indicators\n",
    "    conspiracy_keywords = [\n",
    "        'hiding', 'cover up', 'secret', 'conspiracy', 'they don\\'t want you to know',\n",
    "        'suppressed', 'censored', 'banned', 'forbidden'\n",
    "    ]\n",
    "    conspiracy_matches = [word for word in conspiracy_keywords if word in claim_lower]\n",
    "    if conspiracy_matches:\n",
    "        detected_cues.append({\n",
    "            'type': ManipulationCue.CONSPIRACY.value,\n",
    "            'confidence': min(len(conspiracy_matches) * 0.6, 1.0),\n",
    "            'evidence': conspiracy_matches,\n",
    "            'description': 'Suggests conspiracy or cover-up without evidence'\n",
    "        })\n",
    "    \n",
    "    # Urgency\n",
    "    urgency_keywords = [\n",
    "        'immediately', 'urgent', 'breaking', 'emergency', 'critical',\n",
    "        'must act now', 'time running out', 'before it\\'s too late'\n",
    "    ]\n",
    "    urgency_matches = [word for word in urgency_keywords if word in claim_lower]\n",
    "    if urgency_matches:\n",
    "        detected_cues.append({\n",
    "            'type': ManipulationCue.URGENCY.value,\n",
    "            'confidence': min(len(urgency_matches) * 0.4, 1.0),\n",
    "            'evidence': urgency_matches,\n",
    "            'description': 'Creates false sense of urgency to prevent critical evaluation'\n",
    "        })\n",
    "    \n",
    "    return detected_cues\n",
    "\n",
    "# Test manipulation cue detection\n",
    "test_claims = [\n",
    "    \"The new COVID vaccine causes severe side effects in 80% of patients\",\n",
    "    \"SHOCKING: Doctors don't want you to know this DEADLY secret about vaccines!\",\n",
    "    \"BREAKING: Scientists discover miracle cure but government is hiding it!\",\n",
    "    \"Studies show vaccines are safe and effective for most people\"\n",
    "]\n",
    "\n",
    "print(\"Manipulation cue detection results:\")\n",
    "for claim in test_claims:\n",
    "    cues = detect_manipulation_cues(claim)\n",
    "    print(f\"\\nClaim: {claim}\")\n",
    "    print(f\"Manipulation cues found: {len(cues)}\")\n",
    "    for cue in cues:\n",
    "        print(f\"  - {cue['type']}: {cue['description']} (confidence: {cue['confidence']:.2f})\")\n",
    "        print(f\"    Evidence: {cue['evidence']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db82162a",
   "metadata": {},
   "source": [
    "## Step 3: Misleading Context Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad7205d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_misleading_context(claim: str, verdict: str, citations: List[Dict]) -> Dict[str, any]:\n",
    "    \"\"\"Analyze why the claim is misleading based on evidence\"\"\"\n",
    "    misleading_factors = []\n",
    "    \n",
    "    # Factor 1: Statistical manipulation\n",
    "    if '80%' in claim and verdict == 'REFUTED':\n",
    "        # Look for actual statistics in citations\n",
    "        actual_stats = []\n",
    "        for citation in citations:\n",
    "            snippet = citation.get('highlighted_snippet', '')\n",
    "            if '5%' in snippet or 'less than' in snippet:\n",
    "                actual_stats.append('less than 5%')\n",
    "        \n",
    "        if actual_stats:\n",
    "            misleading_factors.append({\n",
    "                'type': 'statistical_exaggeration',\n",
    "                'severity': 'high',\n",
    "                'description': f\"Claim states 80% but evidence shows {actual_stats[0]}\",\n",
    "                'explanation': \"The claim grossly exaggerates the actual rate by a factor of 16x\"\n",
    "            })\n",
    "    \n",
    "    # Factor 2: Missing context\n",
    "    context_indicators = [\n",
    "        ('side effects', 'mild', 'Claim omits that most side effects are mild'),\n",
    "        ('vaccine', 'safe', 'Claim ignores overall safety profile'),\n",
    "        ('patients', 'clinical trials', 'Claim doesn\\'t specify the study context')\n",
    "    ]\n",
    "    \n",
    "    for claim_term, context_term, explanation in context_indicators:\n",
    "        if claim_term in claim.lower():\n",
    "            # Check if context is provided in citations\n",
    "            context_found = any(context_term in citation.get('highlighted_snippet', '').lower() \n",
    "                              for citation in citations)\n",
    "            if context_found:\n",
    "                misleading_factors.append({\n",
    "                    'type': 'missing_context',\n",
    "                    'severity': 'medium',\n",
    "                    'description': explanation,\n",
    "                    'explanation': f\"Important context about '{context_term}' is missing from the claim\"\n",
    "                })\n",
    "    \n",
    "    # Factor 3: Source credibility issues\n",
    "    if not any('government' in citation.get('source', '').lower() or \n",
    "               'who' in citation.get('source', '').lower() or\n",
    "               'official' in citation.get('source', '').lower()\n",
    "               for citation in citations):\n",
    "        misleading_factors.append({\n",
    "            'type': 'lack_of_authoritative_source',\n",
    "            'severity': 'medium',\n",
    "            'description': 'Claim lacks backing from authoritative health sources',\n",
    "            'explanation': 'No credible health authorities support this claim'\n",
    "        })\n",
    "    \n",
    "    # Factor 4: Contradicts scientific consensus\n",
    "    if verdict == 'REFUTED' and len(citations) >= 2:\n",
    "        all_refute = all(citation.get('stance') == 'REFUTED' for citation in citations)\n",
    "        if all_refute:\n",
    "            misleading_factors.append({\n",
    "                'type': 'contradicts_consensus',\n",
    "                'severity': 'high',\n",
    "                'description': 'Claim directly contradicts scientific consensus',\n",
    "                'explanation': f\"Multiple authoritative sources ({len(citations)}) contradict this claim\"\n",
    "            })\n",
    "    \n",
    "    return {\n",
    "        'misleading_factors': misleading_factors,\n",
    "        'severity_score': sum(1 if f['severity'] == 'high' else 0.5 for f in misleading_factors),\n",
    "        'total_factors': len(misleading_factors)\n",
    "    }\n",
    "\n",
    "# Test misleading context analysis\n",
    "misleading_analysis = analyze_misleading_context(\n",
    "    test_phase4_output['claim'],\n",
    "    test_phase4_output['verdict'],\n",
    "    test_phase4_output['citations']\n",
    ")\n",
    "\n",
    "print(\"Misleading context analysis:\")\n",
    "print(f\"Total misleading factors: {misleading_analysis['total_factors']}\")\n",
    "print(f\"Severity score: {misleading_analysis['severity_score']:.1f}\")\n",
    "print(\"\\nMisleading factors detected:\")\n",
    "\n",
    "for factor in misleading_analysis['misleading_factors']:\n",
    "    severity_emoji = '🔴' if factor['severity'] == 'high' else '🟡'\n",
    "    print(f\"  {severity_emoji} {factor['type'].replace('_', ' ').title()}\")\n",
    "    print(f\"    Description: {factor['description']}\")\n",
    "    print(f\"    Explanation: {factor['explanation']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e295e21e",
   "metadata": {},
   "source": [
    "## Step 4: Manipulation Cue Chips Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535cb4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_manipulation_chips(manipulation_cues: List[Dict]) -> List[Dict[str, any]]:\n",
    "    \"\"\"Generate user-friendly manipulation cue chips\"\"\"\n",
    "    chip_templates = {\n",
    "        ManipulationCue.FEAR_APPEAL.value: {\n",
    "            'emoji': '😰',\n",
    "            'title': 'Fear Appeal',\n",
    "            'short_description': 'Uses scary language',\n",
    "            'explanation': 'This content uses fear-inducing words to make you feel anxious and bypass critical thinking.',\n",
    "            'tip': 'Ask yourself: Are the fears justified by evidence?'\n",
    "        },\n",
    "        ManipulationCue.SPECIFIC_NUMBERS.value: {\n",
    "            'emoji': '📊',\n",
    "            'title': 'Questionable Statistics',\n",
    "            'short_description': 'Precise numbers without source',\n",
    "            'explanation': 'Specific percentages or numbers can seem authoritative but may lack credible sources.',\n",
    "            'tip': 'Always ask: Where do these numbers come from?'\n",
    "        },\n",
    "        ManipulationCue.EMOTIONAL_LANGUAGE.value: {\n",
    "            'emoji': '💢',\n",
    "            'title': 'Emotional Language',\n",
    "            'short_description': 'Designed to trigger emotions',\n",
    "            'explanation': 'Strong emotional words are used to provoke reactions rather than encourage thinking.',\n",
    "            'tip': 'Take a breath and focus on facts, not feelings.'\n",
    "        },\n",
    "        ManipulationCue.FALSE_AUTHORITY.value: {\n",
    "            'emoji': '👨‍⚕️',\n",
    "            'title': 'Vague Authority',\n",
    "            'short_description': 'Claims expert support without names',\n",
    "            'explanation': 'References to \"doctors\" or \"experts\" without specific names or credentials.',\n",
    "            'tip': 'Look for specific, named, and qualified sources.'\n",
    "        },\n",
    "        ManipulationCue.CONSPIRACY.value: {\n",
    "            'emoji': '🕵️',\n",
    "            'title': 'Conspiracy Thinking',\n",
    "            'short_description': 'Suggests hidden agenda',\n",
    "            'explanation': 'Implies that information is being hidden or suppressed without providing evidence.',\n",
    "            'tip': 'Extraordinary claims require extraordinary evidence.'\n",
    "        },\n",
    "        ManipulationCue.URGENCY.value: {\n",
    "            'emoji': '⏰',\n",
    "            'title': 'False Urgency',\n",
    "            'short_description': 'Pressures quick action',\n",
    "            'explanation': 'Creates time pressure to prevent you from fact-checking or thinking critically.',\n",
    "            'tip': 'Important decisions deserve time for verification.'\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    chips = []\n",
    "    for cue in manipulation_cues:\n",
    "        cue_type = cue['type']\n",
    "        if cue_type in chip_templates:\n",
    "            template = chip_templates[cue_type]\n",
    "            chip = {\n",
    "                'id': f\"chip_{cue_type}\",\n",
    "                'emoji': template['emoji'],\n",
    "                'title': template['title'],\n",
    "                'short_description': template['short_description'],\n",
    "                'explanation': template['explanation'],\n",
    "                'tip': template['tip'],\n",
    "                'confidence': cue['confidence'],\n",
    "                'evidence': cue['evidence'],\n",
    "                'severity': 'high' if cue['confidence'] > 0.7 else 'medium' if cue['confidence'] > 0.4 else 'low'\n",
    "            }\n",
    "            chips.append(chip)\n",
    "    \n",
    "    # Sort by confidence (most confident first)\n",
    "    chips.sort(key=lambda x: x['confidence'], reverse=True)\n",
    "    \n",
    "    return chips\n",
    "\n",
    "def format_chips_for_display(chips: List[Dict]) -> Dict[str, any]:\n",
    "    \"\"\"Format chips for user interface display\"\"\"\n",
    "    if not chips:\n",
    "        return {\n",
    "            'count': 0,\n",
    "            'chips': [],\n",
    "            'overall_manipulation_score': 0.0\n",
    "        }\n",
    "    \n",
    "    # Calculate overall manipulation score\n",
    "    overall_score = sum(chip['confidence'] for chip in chips) / len(chips)\n",
    "    \n",
    "    # Format for display\n",
    "    formatted_chips = []\n",
    "    for chip in chips:\n",
    "        formatted_chip = {\n",
    "            'id': chip['id'],\n",
    "            'display_text': f\"{chip['emoji']} {chip['title']}\",\n",
    "            'tooltip': chip['short_description'],\n",
    "            'full_explanation': chip['explanation'],\n",
    "            'action_tip': chip['tip'],\n",
    "            'severity': chip['severity'],\n",
    "            'evidence_count': len(chip['evidence']) if isinstance(chip['evidence'], list) else 1\n",
    "        }\n",
    "        formatted_chips.append(formatted_chip)\n",
    "    \n",
    "    return {\n",
    "        'count': len(chips),\n",
    "        'chips': formatted_chips,\n",
    "        'overall_manipulation_score': overall_score,\n",
    "        'manipulation_level': 'high' if overall_score > 0.7 else 'medium' if overall_score > 0.4 else 'low'\n",
    "    }\n",
    "\n",
    "# Test manipulation chip generation\n",
    "manipulation_cues = detect_manipulation_cues(test_phase4_output['claim'])\n",
    "manipulation_chips = generate_manipulation_chips(manipulation_cues)\n",
    "formatted_chips = format_chips_for_display(manipulation_chips)\n",
    "\n",
    "print(\"Manipulation cue chips:\")\n",
    "print(f\"Total chips: {formatted_chips['count']}\")\n",
    "print(f\"Overall manipulation level: {formatted_chips['manipulation_level']}\")\n",
    "print(f\"Manipulation score: {formatted_chips['overall_manipulation_score']:.2f}\")\n",
    "print(\"\\nGenerated chips:\")\n",
    "\n",
    "for chip in formatted_chips['chips']:\n",
    "    severity_indicator = '🔴' if chip['severity'] == 'high' else '🟡' if chip['severity'] == 'medium' else '🟢'\n",
    "    print(f\"\\n{severity_indicator} {chip['display_text']}\")\n",
    "    print(f\"   Tooltip: {chip['tooltip']}\")\n",
    "    print(f\"   Explanation: {chip['full_explanation']}\")\n",
    "    print(f\"   Tip: {chip['action_tip']}\")\n",
    "    print(f\"   Evidence count: {chip['evidence_count']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5168932e",
   "metadata": {},
   "source": [
    "## Step 5: Prebunk Tip Card Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5962d4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prebunk_tip_card(claim: str, verdict: str, manipulation_chips: List[Dict], misleading_analysis: Dict) -> Dict[str, any]:\n",
    "    \"\"\"Generate educational prebunk tip card (20 second read)\"\"\"\n",
    "    \n",
    "    # Determine card theme based on verdict and manipulation level\n",
    "    if verdict == 'REFUTED':\n",
    "        card_theme = 'false_claim'\n",
    "        primary_color = '#ff4444'\n",
    "        icon = '❌'\n",
    "    elif verdict == 'SUPPORTED':\n",
    "        card_theme = 'accurate_claim'\n",
    "        primary_color = '#44ff44'\n",
    "        icon = '✅'\n",
    "    else:\n",
    "        card_theme = 'unclear_claim'\n",
    "        primary_color = '#ffaa00'\n",
    "        icon = '❓'\n",
    "    \n",
    "    # Generate main takeaway\n",
    "    if verdict == 'REFUTED':\n",
    "        main_takeaway = \"This claim contains false information that contradicts credible sources.\"\n",
    "    elif verdict == 'SUPPORTED':\n",
    "        main_takeaway = \"This claim is supported by credible evidence and sources.\"\n",
    "    else:\n",
    "        main_takeaway = \"This claim needs more evidence for a definitive conclusion.\"\n",
    "    \n",
    "    # Generate key learning points (max 3 for 20-second read)\n",
    "    learning_points = []\n",
    "    \n",
    "    # Point 1: Most important manipulation technique\n",
    "    if manipulation_chips:\n",
    "        top_chip = manipulation_chips[0]  # Highest confidence\n",
    "        learning_points.append({\n",
    "            'icon': top_chip['emoji'],\n",
    "            'title': f\"Watch for {top_chip['title']}\",\n",
    "            'description': top_chip['tip']\n",
    "        })\n",
    "    \n",
    "    # Point 2: Source verification\n",
    "    learning_points.append({\n",
    "        'icon': '🔍',\n",
    "        'title': 'Check the Source',\n",
    "        'description': 'Look for specific, named experts and official health organizations.'\n",
    "    })\n",
    "    \n",
    "    # Point 3: Statistical awareness\n",
    "    if any('statistical' in factor['type'] for factor in misleading_analysis.get('misleading_factors', [])):\n",
    "        learning_points.append({\n",
    "            'icon': '📊',\n",
    "            'title': 'Question Statistics',\n",
    "            'description': 'Ask where numbers come from and if they\\'re from credible studies.'\n",
    "        })\n",
    "    else:\n",
    "        learning_points.append({\n",
    "            'icon': '🧠',\n",
    "            'title': 'Think Critically',\n",
    "            'description': 'Pause before sharing. Does this claim sound too extreme?'\n",
    "        })\n",
    "    \n",
    "    # Generate action steps\n",
    "    action_steps = [\n",
    "        \"Verify with official health sources (WHO, CDC, government health departments)\",\n",
    "        \"Look for peer-reviewed studies and multiple confirming sources\",\n",
    "        \"Be skeptical of claims with extreme statistics or emotional language\"\n",
    "    ]\n",
    "    \n",
    "    # Generate related topics for further learning\n",
    "    related_topics = []\n",
    "    if 'vaccine' in claim.lower():\n",
    "        related_topics = ['Vaccine Safety', 'Clinical Trials', 'Adverse Event Reporting']\n",
    "    elif 'covid' in claim.lower():\n",
    "        related_topics = ['COVID-19 Facts', 'Pandemic Response', 'Health Misinformation']\n",
    "    else:\n",
    "        related_topics = ['Fact-Checking', 'Source Evaluation', 'Critical Thinking']\n",
    "    \n",
    "    # Calculate reading time (average 200 words per minute)\n",
    "    word_count = len(main_takeaway.split()) + sum(len(lp['description'].split()) for lp in learning_points)\n",
    "    reading_time = max(15, min(25, (word_count / 200) * 60))  # 15-25 seconds\n",
    "    \n",
    "    return {\n",
    "        'id': f\"prebunk_card_{datetime.now().strftime('%Y%m%d_%H%M%S')}\",\n",
    "        'theme': card_theme,\n",
    "        'icon': icon,\n",
    "        'primary_color': primary_color,\n",
    "        'title': f\"Fact-Check: {verdict.title()} Claim\",\n",
    "        'main_takeaway': main_takeaway,\n",
    "        'learning_points': learning_points,\n",
    "        'action_steps': action_steps,\n",
    "        'related_topics': related_topics,\n",
    "        'reading_time_seconds': int(reading_time),\n",
    "        'created_at': datetime.now().isoformat(),\n",
    "        'claim_snippet': claim[:80] + '...' if len(claim) > 80 else claim\n",
    "    }\n",
    "\n",
    "# Test prebunk tip card generation\n",
    "prebunk_card = generate_prebunk_tip_card(\n",
    "    test_phase4_output['claim'],\n",
    "    test_phase4_output['verdict'],\n",
    "    manipulation_chips,\n",
    "    misleading_analysis\n",
    ")\n",
    "\n",
    "print(\"Generated Prebunk Tip Card:\")\n",
    "print(f\"\\n{prebunk_card['icon']} {prebunk_card['title']}\")\n",
    "print(f\"Reading time: {prebunk_card['reading_time_seconds']} seconds\")\n",
    "print(f\"\\nMain takeaway:\")\n",
    "print(f\"  {prebunk_card['main_takeaway']}\")\n",
    "\n",
    "print(f\"\\nKey learning points:\")\n",
    "for i, point in enumerate(prebunk_card['learning_points'], 1):\n",
    "    print(f\"  {i}. {point['icon']} {point['title']}\")\n",
    "    print(f\"     {point['description']}\")\n",
    "\n",
    "print(f\"\\nAction steps:\")\n",
    "for i, step in enumerate(prebunk_card['action_steps'], 1):\n",
    "    print(f\"  {i}. {step}\")\n",
    "\n",
    "print(f\"\\nRelated topics: {', '.join(prebunk_card['related_topics'])}\")\n",
    "print(f\"\\nClaim snippet: {prebunk_card['claim_snippet']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39878321",
   "metadata": {},
   "source": [
    "## Step 6: Educational Content Personalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c253c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def personalize_educational_content(user_profile: Dict, prebunk_card: Dict) -> Dict[str, any]:\n",
    "    \"\"\"Personalize educational content based on user profile\"\"\"\n",
    "    \n",
    "    # Default user profile for demo\n",
    "    default_profile = {\n",
    "        'age_group': 'adult',  # young, adult, senior\n",
    "        'education_level': 'college',  # high_school, college, graduate\n",
    "        'health_literacy': 'medium',  # low, medium, high\n",
    "        'preferred_language': 'english',\n",
    "        'misinformation_vulnerability': 'medium',  # low, medium, high\n",
    "        'previous_interactions': 3\n",
    "    }\n",
    "    \n",
    "    profile = {**default_profile, **user_profile}\n",
    "    \n",
    "    # Adjust content complexity\n",
    "    if profile['education_level'] == 'high_school' or profile['health_literacy'] == 'low':\n",
    "        complexity_level = 'simple'\n",
    "        vocab_adjustment = 'basic'\n",
    "    elif profile['education_level'] == 'graduate' and profile['health_literacy'] == 'high':\n",
    "        complexity_level = 'advanced'\n",
    "        vocab_adjustment = 'technical'\n",
    "    else:\n",
    "        complexity_level = 'moderate'\n",
    "        vocab_adjustment = 'standard'\n",
    "    \n",
    "    # Adjust explanation depth\n",
    "    if profile['misinformation_vulnerability'] == 'high':\n",
    "        explanation_depth = 'detailed'\n",
    "        include_inoculation = True\n",
    "    else:\n",
    "        explanation_depth = 'concise'\n",
    "        include_inoculation = False\n",
    "    \n",
    "    # Personalized learning points\n",
    "    personalized_points = []\n",
    "    base_points = prebunk_card['learning_points']\n",
    "    \n",
    "    for point in base_points:\n",
    "        personalized_point = point.copy()\n",
    "        \n",
    "        # Adjust language complexity\n",
    "        if vocab_adjustment == 'basic':\n",
    "            # Simplify technical terms\n",
    "            personalized_point['description'] = personalized_point['description'].replace(\n",
    "                'peer-reviewed studies', 'official research'\n",
    "            ).replace(\n",
    "                'credible studies', 'trustworthy research'\n",
    "            )\n",
    "        elif vocab_adjustment == 'technical':\n",
    "            # Add more technical detail\n",
    "            if 'statistics' in personalized_point['description'].lower():\n",
    "                personalized_point['description'] += ' Check methodology and sample size.'\n",
    "        \n",
    "        personalized_points.append(personalized_point)\n",
    "    \n",
    "    # Add inoculation content if needed\n",
    "    inoculation_content = None\n",
    "    if include_inoculation:\n",
    "        inoculation_content = {\n",
    "            'title': 'Be Prepared for Similar Claims',\n",
    "            'description': 'You might see similar false claims about vaccines or health treatments. Use the same critical thinking skills.',\n",
    "            'warning_signs': [\n",
    "                'Extreme percentages without sources',\n",
    "                'Claims that \"authorities don\\'t want you to know\"',\n",
    "                'Emotional language designed to scare'\n",
    "            ]\n",
    "        }\n",
    "    \n",
    "    # Adjust reading time based on complexity\n",
    "    base_time = prebunk_card['reading_time_seconds']\n",
    "    if complexity_level == 'simple':\n",
    "        adjusted_time = int(base_time * 0.8)  # Faster read\n",
    "    elif complexity_level == 'advanced':\n",
    "        adjusted_time = int(base_time * 1.3)  # Slower read\n",
    "    else:\n",
    "        adjusted_time = base_time\n",
    "    \n",
    "    return {\n",
    "        'personalized_card': {\n",
    "            **prebunk_card,\n",
    "            'learning_points': personalized_points,\n",
    "            'reading_time_seconds': adjusted_time,\n",
    "            'complexity_level': complexity_level,\n",
    "            'explanation_depth': explanation_depth,\n",
    "            'inoculation_content': inoculation_content\n",
    "        },\n",
    "        'personalization_metadata': {\n",
    "            'user_profile': profile,\n",
    "            'adjustments_made': {\n",
    "                'complexity_level': complexity_level,\n",
    "                'vocab_adjustment': vocab_adjustment,\n",
    "                'explanation_depth': explanation_depth,\n",
    "                'include_inoculation': include_inoculation\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Test personalization for different user types\n",
    "user_profiles = [\n",
    "    {\n",
    "        'name': 'High School Student',\n",
    "        'education_level': 'high_school',\n",
    "        'health_literacy': 'low',\n",
    "        'misinformation_vulnerability': 'high'\n",
    "    },\n",
    "    {\n",
    "        'name': 'College Graduate',\n",
    "        'education_level': 'college',\n",
    "        'health_literacy': 'medium',\n",
    "        'misinformation_vulnerability': 'medium'\n",
    "    },\n",
    "    {\n",
    "        'name': 'Healthcare Professional',\n",
    "        'education_level': 'graduate',\n",
    "        'health_literacy': 'high',\n",
    "        'misinformation_vulnerability': 'low'\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"Personalized educational content:\")\n",
    "for profile in user_profiles:\n",
    "    personalized = personalize_educational_content(profile, prebunk_card)\n",
    "    card = personalized['personalized_card']\n",
    "    meta = personalized['personalization_metadata']\n",
    "    \n",
    "    print(f\"\\n=== {profile['name']} ===\")\n",
    "    print(f\"Complexity level: {card['complexity_level']}\")\n",
    "    print(f\"Reading time: {card['reading_time_seconds']} seconds\")\n",
    "    print(f\"Vocab adjustment: {meta['adjustments_made']['vocab_adjustment']}\")\n",
    "    print(f\"Include inoculation: {meta['adjustments_made']['include_inoculation']}\")\n",
    "    \n",
    "    if card['inoculation_content']:\n",
    "        print(f\"Inoculation content: {card['inoculation_content']['title']}\")\n",
    "    \n",
    "    # Show first learning point to see personalization\n",
    "    if card['learning_points']:\n",
    "        first_point = card['learning_points'][0]\n",
    "        print(f\"Sample learning point: {first_point['title']} - {first_point['description'][:60]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c48400b",
   "metadata": {},
   "source": [
    "## Step 7: Complete Phase 5 Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7fa508",
   "metadata": {},
   "outputs": [],
   "source": [
    "def phase5_pipeline(phase4_output: Dict, user_profile: Optional[Dict] = None) -> Dict[str, any]:\n",
    "    \"\"\"Complete Phase 5 pipeline: User Explanation Layer\"\"\"\n",
    "    pipeline_result = {\n",
    "        'phase': 'Phase 5 - User Explanation Layer',\n",
    "        'input_claim': phase4_output['claim'],\n",
    "        'steps': []\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        claim = phase4_output['claim']\n",
    "        verdict = phase4_output['verdict']\n",
    "        citations = phase4_output['citations']\n",
    "        \n",
    "        # Step 1: Detect manipulation cues\n",
    "        manipulation_cues = detect_manipulation_cues(claim)\n",
    "        pipeline_result['steps'].append({\n",
    "            'step': 'manipulation_detection',\n",
    "            'result': {\n",
    "                'cues_detected': len(manipulation_cues),\n",
    "                'cue_types': [cue['type'] for cue in manipulation_cues]\n",
    "            }\n",
    "        })\n",
    "        \n",
    "        # Step 2: Analyze misleading context\n",
    "        misleading_analysis = analyze_misleading_context(claim, verdict, citations)\n",
    "        pipeline_result['steps'].append({\n",
    "            'step': 'misleading_analysis',\n",
    "            'result': misleading_analysis\n",
    "        })\n",
    "        \n",
    "        # Step 3: Generate manipulation chips\n",
    "        manipulation_chips = generate_manipulation_chips(manipulation_cues)\n",
    "        formatted_chips = format_chips_for_display(manipulation_chips)\n",
    "        pipeline_result['steps'].append({\n",
    "            'step': 'manipulation_chips',\n",
    "            'result': formatted_chips\n",
    "        })\n",
    "        \n",
    "        # Step 4: Generate prebunk tip card\n",
    "        prebunk_card = generate_prebunk_tip_card(claim, verdict, manipulation_chips, misleading_analysis)\n",
    "        pipeline_result['steps'].append({\n",
    "            'step': 'prebunk_card_generation',\n",
    "            'result': prebunk_card\n",
    "        })\n",
    "        \n",
    "        # Step 5: Personalize content (if user profile provided)\n",
    "        if user_profile:\n",
    "            personalized_content = personalize_educational_content(user_profile, prebunk_card)\n",
    "            final_card = personalized_content['personalized_card']\n",
    "            personalization_meta = personalized_content['personalization_metadata']\n",
    "        else:\n",
    "            final_card = prebunk_card\n",
    "            personalization_meta = None\n",
    "        \n",
    "        pipeline_result['steps'].append({\n",
    "            'step': 'content_personalization',\n",
    "            'result': {\n",
    "                'personalized': user_profile is not None,\n",
    "                'personalization_metadata': personalization_meta\n",
    "            }\n",
    "        })\n",
    "        \n",
    "        # Final output\n",
    "        pipeline_result['final_output'] = {\n",
    "            'claim': claim,\n",
    "            'verdict_summary': f\"{phase4_output['confidence_badge']['emoji']} {verdict} ({phase4_output['certainty_level']} Confidence)\",\n",
    "            'manipulation_chips': formatted_chips,\n",
    "            'misleading_factors': misleading_analysis['misleading_factors'],\n",
    "            'prebunk_card': final_card,\n",
    "            'education_summary': {\n",
    "                'manipulation_level': formatted_chips['manipulation_level'],\n",
    "                'learning_points_count': len(final_card['learning_points']),\n",
    "                'reading_time': final_card['reading_time_seconds'],\n",
    "                'personalized': user_profile is not None\n",
    "            },\n",
    "            'ready_for_phase6': True\n",
    "        }\n",
    "        pipeline_result['status'] = 'success'\n",
    "        \n",
    "    except Exception as e:\n",
    "        pipeline_result['error'] = str(e)\n",
    "        pipeline_result['status'] = 'failed'\n",
    "    \n",
    "    return pipeline_result\n",
    "\n",
    "# Test complete Phase 5 pipeline\n",
    "print(\"=== Testing Complete Phase 5 Pipeline ===\")\n",
    "\n",
    "# Test without personalization\n",
    "phase5_result_basic = phase5_pipeline(test_phase4_output)\n",
    "print(f\"Basic pipeline status: {phase5_result_basic['status']}\")\n",
    "\n",
    "# Test with personalization\n",
    "test_user_profile = {\n",
    "    'education_level': 'college',\n",
    "    'health_literacy': 'medium',\n",
    "    'misinformation_vulnerability': 'high'\n",
    "}\n",
    "phase5_result_personalized = phase5_pipeline(test_phase4_output, test_user_profile)\n",
    "\n",
    "# Print summary\n",
    "final_output = phase5_result_personalized['final_output']\n",
    "print(f\"\\nPersonalized pipeline status: {phase5_result_personalized['status']}\")\n",
    "print(f\"\\nFinal output summary:\")\n",
    "print(f\"  Claim: {final_output['claim'][:60]}...\")\n",
    "print(f\"  Verdict: {final_output['verdict_summary']}\")\n",
    "print(f\"  Manipulation chips: {final_output['manipulation_chips']['count']}\")\n",
    "print(f\"  Manipulation level: {final_output['manipulation_chips']['manipulation_level']}\")\n",
    "print(f\"  Misleading factors: {len(final_output['misleading_factors'])}\")\n",
    "print(f\"  Learning points: {final_output['education_summary']['learning_points_count']}\")\n",
    "print(f\"  Reading time: {final_output['education_summary']['reading_time']} seconds\")\n",
    "print(f\"  Personalized: {final_output['education_summary']['personalized']}\")\n",
    "print(f\"  Ready for Phase 6: {final_output['ready_for_phase6']}\")\n",
    "\n",
    "# Show manipulation chips\n",
    "print(f\"\\nDetected manipulation techniques:\")\n",
    "for chip in final_output['manipulation_chips']['chips']:\n",
    "    print(f\"  - {chip['display_text']}: {chip['tooltip']}\")\n",
    "\n",
    "# Show prebunk card summary\n",
    "card = final_output['prebunk_card']\n",
    "print(f\"\\nPrebunk card: {card['title']}\")\n",
    "print(f\"  Main takeaway: {card['main_takeaway'][:80]}...\")\n",
    "print(f\"  Learning points: {len(card['learning_points'])}\")\n",
    "print(f\"  Related topics: {', '.join(card['related_topics'])}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
